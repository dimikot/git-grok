#!/usr/bin/env python3
from __future__ import annotations
import argparse
import hashlib
import json
import os
import random
import re
import shlex
import signal
import subprocess
import sys
import traceback
from dataclasses import dataclass
from datetime import datetime
from itertools import dropwhile
from subprocess import CalledProcessError, Popen, check_output
from threading import Thread, current_thread, main_thread
from time import time, sleep
from typing import Callable, Literal, TypeVar, Generic

BRANCH_PREFIX = "grok/"
PR_HEADER = "Pull Request"
PR_HEADER_RE = rf"^\s+{PR_HEADER}: (https://\S+)(?: \((.*?)\))?"
MIDDLE_PR_LABEL = "git-grok-middle-pr"
MIDDLE_PR_LABEL_DESCRIPTION = "This PR is in the middle of the stack."
MIDDLE_PR_LABEL_COLOR = "CCCCCC"
BODY_SUFFIX_TITLE = "## PRs in the Stack"
BODY_SUFFIX_FOOTER = (
    "(The stack is managed by [git-grok](https://github.com/dimikot/git-grok).)"
)
BODY_SUFFIX_RE = (
    rf"^ {re.escape(BODY_SUFFIX_TITLE)} [^\n]* \n"
    + r"( (\s*(\n|\Z))* (- \s* [^\n]+ (\n|\Z)) )*"
    + r"( (\s*(\n|\Z))* [^\n]+ \bgit-grok\b [^\n]+ (\n|\Z) )?"
)
MIN_BRANCH_LEN_IN_PRINT = 36
MIN_TITLE_LEN_IN_PRINT = 36
TMP_BODY_FILE = "/tmp/git-grok.body"
INTERNAL_ENV_VAR_PREFIX = "GIT_GROK"
INTERNAL_IN_REBASE_INTERACTIVE_VAR = f"{INTERNAL_ENV_VAR_PREFIX}_in_rebase_interactive"
INTERNAL_SKIP_UPDATE_PRS_VAR = f"{INTERNAL_ENV_VAR_PREFIX}_skip_update_prs"
DEBUG_FILE = "/tmp/git-grok.log"
DEBUG_COLOR_GRAY_1 = (128, 128, 128)
DEBUG_COLOR_GRAY_2 = (92, 92, 92)
GH_MIN_VERSION = "2.29.0"

try:
    TERMINAL_SIZE = os.get_terminal_size()
    os.environ["COLUMNS"] = str(TERMINAL_SIZE.columns)
    os.environ["LINES"] = str(TERMINAL_SIZE.lines)
except:
    TERMINAL_SIZE = os.terminal_size(  # type: ignore
        (
            int(os.environ.get("COLUMNS", "512")),
            int(os.environ.get("LINES", "40")),
        )
    )


#
# A parsed commit from the local git folder.
#
@dataclass
class Commit:
    hash: str
    url: str | None
    title: str
    description: str
    branch: str | None


#
# A parsed remote PR loaded from GitHub.
#
@dataclass
class Pr:
    number: int
    title: str
    body: str
    base_branch: str
    head_branch: str
    url: str
    review_decision: PrReviewDecision
    state: Literal["OPEN", "CLOSED", "MERGED"]
    auto_merge_status: Literal["ENABLED", "DISABLED"]
    labels: list[str]
    commit_hashes: list[str]

    def is_accidentally_merged(self) -> bool:
        return self.state == "MERGED" and self.base_branch.startswith(BRANCH_PREFIX)

    def is_closed_and_non_openable(self) -> bool:
        return self.state == "CLOSED" and len(self.commit_hashes) == 0


#
# A pair of commit hash and branch name.
#
@dataclass
class Branch:
    hash: str
    branch: str


#
# Some data passed from the main process to each individual child process call
# within "git rebase -i", for each commit in the stack.
#
@dataclass
class InRebaseInteractiveData:
    commit_index_one_based: int
    total_commits_in_stack: int

    @staticmethod
    def parse(str: str) -> InRebaseInteractiveData | None:
        if m := re.match(r"^(\d+)/(\d+)$", str):
            return InRebaseInteractiveData(
                commit_index_one_based=int(m.group(1)),
                total_commits_in_stack=int(m.group(2)),
            )
        return None

    def stringify(self) -> str:
        return f"{self.commit_index_one_based}/{self.total_commits_in_stack}"


BranchPushResult = Literal["pushed", "up-to-date"]

BranchType = Literal["base", "head"]

PrUpsertResult = Literal["created", "updated", "up-to-date", "reopened"]

PrReviewDecision = Literal["APPROVED", "REVIEW_REQUIRED", "CHANGES_REQUESTED"]

CommitUpdateResult = Literal["updated", "up-to-date"]

T = TypeVar("T")


class Main:
    debug: bool = False
    debug_force_push_branches: bool = False
    login: str
    remote: str
    remote_base_branch: str = "master"
    in_rebase_interactive: InRebaseInteractiveData | None = None

    #
    # Main entry point.
    #
    def run(self):
        self.debug_log_argv()

        parser = argparse.ArgumentParser(
            description="Pushes local commits as stacked PRs on GitHub and keeps them in sync.",
        )
        parser.add_argument(
            "--debug",
            default=False,
            action="store_true",
            help="print git and gh command lines",
        )
        parser.add_argument(
            "--debug-force-push-branches",
            default=False,
            action="store_true",
            help="if passed, forces all branches to be re-created and re-pushed",
        )
        args = parser.parse_args()

        self.in_rebase_interactive = InRebaseInteractiveData.parse(
            os.environ.get(INTERNAL_IN_REBASE_INTERACTIVE_VAR, "")
        )

        self.debug = args.debug
        self.debug_force_push_branches = args.debug_force_push_branches

        if not self.in_rebase_interactive:
            self.gh_verify_version()
            self.git_verify_version()
            self.self_update()
            # For debug purposes only.
            self.shell_no_throw(["git", "status"])
            self.shell_no_throw(["git", "log", "--graph", "--decorate", "-3"])

        # Below is the real work.
        self.login = self.cache_through(
            "gh_get_current_login",
            self.gh_get_current_login,
        )
        self.remote = self.cache_through(
            "git_get_current_remote",
            self.git_get_current_remote,
        )
        self.remote_base_branch = self.cache_through(
            "git_get_current_remote_base_branch",
            self.git_get_current_remote_base_branch,
        )
        if not self.in_rebase_interactive:
            self.run_all()
        else:
            self.run_in_rebase_interactive(data=self.in_rebase_interactive)

    #
    # Assuming all PRs in the stack already have PR URLs in their description,
    # pushes the updated branches and updates the PRs descriptions with the full
    # list of commits in the stack.
    #
    def run_all(self):
        commits = self.git_get_commits()
        if len(commits) == 0:
            self.print_header(
                f"There are no local commits on top of {self.remote}. Commit something and rerun."
            )
            return

        task_upsert_labels = Task(self.gh_upsert_labels)
        tasks_gh_get_pr = dict(
            (url, Task(self.gh_get_pr, url=url))
            for url in (c.url for c in reversed(commits) if c.url)
        )
        task_upsert_labels.wait()
        prs_by_url = dict((url, task.wait()) for (url, task) in tasks_gh_get_pr.items())

        self.debug_log_commits(commits=commits, prs_by_url=prs_by_url)

        self.process_validate_commits(commits=commits, prs_by_url=prs_by_url)

        # Inject "Pull Request" URL to commit descriptions starting from the
        # commit which doesn't have it. This is a heavy-weighted process which
        # is run for each commit in an interactive rebase, starting from bottom
        # to the very top.
        commit_with_no_url: Commit | None = None
        commit_hashes_to_push_branch: list[str] = []
        for commit in reversed(commits):
            if self.debug_force_push_branches:
                commit_with_no_url = commit
                break
            elif not commit.url:
                commit_with_no_url = commit
                break
            else:
                pr = prs_by_url[commit.url]
                if pr.is_closed_and_non_openable():
                    # If the PR is closed and has 0 commits, there is no way to
                    # reopen it or update its base branch using GitHub API. So
                    # we can only re-create such a PR.
                    commit_with_no_url = commit
                    break
                if pr.is_accidentally_merged():
                    # If the PR was accidentally merged, we need to create a new
                    # PR for the commit, as if no PR existed at all.
                    commit_with_no_url = commit
                    break
                else:
                    # Push this branch and see whether GitHub says that it was
                    # up to date or not.
                    commit_hashes_to_push_branch.append(commit.hash)

        # Some commits have no related PRs (no GitHub URLs in the message)?
        # Create missing PRs and amend their messages (via rebase interactive).
        if commit_with_no_url:
            self.process_create_missing_prs_in_rebase_interactive(
                earliest_hash=commit_with_no_url.hash,
                commits=commits,
            )
            commits = self.git_get_commits()

        # Update PRs for commits; they now all have URLs. Do not push branches
        # for commits for which we have just created missing PRs above (if any),
        # i.e. only push branches for commit_hashes_to_push_branch. This allows
        # to not re-trigger GitHub Actions. Notice that these branches WILL be
        # pushed next time, because we updated the commit message (added "Pull
        # Request" header with the just-created PR URL there which is impossible
        # to predict in advance), i.e. the sequence is "push branch - create PR
        # - update commit message - push branch", but the last step of this
        # sequence is delayed till the next run, when the author has some other
        # updates to piggy-back likely.
        if not os.environ.get(INTERNAL_SKIP_UPDATE_PRS_VAR):
            self.process_update_existing_prs_from_commits_with_urls(
                commits=commits,
                commit_hashes_to_push_branch=commit_hashes_to_push_branch,
            )

    #
    # Runs the sync for only the top commit. This is an internal command which
    # is used during interactive rebase.
    #
    # This workflow runs only when the tool finds a commit that has no PR URL in
    # its description yet. If all commits have existing PR URLs (including the
    # case when they were reordered), the interactive rebase workflow is not
    # run; instead, the branches are just pushed, and the PRs are updated.
    #
    def run_in_rebase_interactive(self, *, data: InRebaseInteractiveData):
        remote_commit = self.git_get_commits(
            latest_ref=f"remotes/{self.remote}/{self.remote_base_branch}",
            count_back_in_time=1,
        )[0]
        commits = self.git_get_commits(latest_ref="HEAD", count_back_in_time=2)
        if len(commits) < 2:
            raise UserException("The repository must have at least 2 commits")
        commit, prev_commit = commits[0], commits[1]

        self.print_header(f"Processing commit: {self.clean_title(commit.title)}")

        to_push: list[Branch] = []
        if prev_commit.hash != remote_commit.hash:
            prev_commit.branch = self.process_commit_infer_branch(commit=prev_commit)
            to_push.append(Branch(hash=prev_commit.hash, branch=prev_commit.branch))
        commit.branch = self.process_commit_infer_branch(commit=commit)
        to_push.append(Branch(hash=commit.hash, branch=commit.branch))

        push_results = self.git_push_branches(branches=to_push)

        if prev_commit.branch in push_results:
            self.print_branch_result(
                type="base",
                branch=prev_commit.branch,
                result=push_results[prev_commit.branch],
            )
        else:
            self.print_branch_result(
                type="base",
                branch=self.remote_base_branch,
                result="up-to-date",
            )

        self.print_branch_result(
            type="head",
            branch=commit.branch,
            result=push_results[commit.branch],
        )

        new_pr_title = commit.title
        new_pr_body = None
        new_pr_is_instead_of = None

        if commit.url:
            pr = self.gh_get_pr(url=commit.url)
            if pr.is_closed_and_non_openable():
                self.print_pr_closed_and_non_openable_no_commits()
                commit.url = None
                new_pr_is_instead_of = "closed and non-openable"
                new_pr_title = pr.title
                new_pr_body = pr.body
            elif pr.is_accidentally_merged():
                self.print_pr_accidentally_merged()
                commit.url = None
                new_pr_is_instead_of = "accidentally merged"
                new_pr_title = pr.title
                new_pr_body = pr.body

        if not commit.url:
            assert (
                commit.branch is not None
            ), f"commit {commit.hash} branch must be resolved"
            url, result = self.gh_create_pr(
                base_branch=prev_commit.branch,
                head_branch=commit.branch,
                title=new_pr_title,
                body=new_pr_body,
                is_middle_pr=(
                    data.commit_index_one_based != 1
                    and data.commit_index_one_based != data.total_commits_in_stack
                ),
            )
            if result != "up-to-date":
                self.print_pr_created(
                    comment=(
                        f"instead of {new_pr_is_instead_of}"
                        if new_pr_is_instead_of
                        else None
                    )
                )
            commit.url = url

            result = self.git_update_current_commit_message(
                header_name=PR_HEADER,
                header_value=commit.url,
                header_comment=self.remote_base_branch,
            )
            if result != "up-to-date":
                self.print_commit_message_updated()
                updated_commit = self.git_get_commits(
                    latest_ref="HEAD",
                    count_back_in_time=1,
                )[0]
                self.git_assign_branch_to_hash(
                    branch=commit.branch,
                    hash=updated_commit.hash,
                )

    #
    # Checks that the tool can process this stack of commits at all.
    #
    def process_validate_commits(
        self,
        *,
        commits: list[Commit],
        prs_by_url: dict[str, Pr],
    ):
        commits_old_to_new = list(reversed(commits))
        for i, commit in list(enumerate(commits_old_to_new))[1:]:
            pr = prs_by_url.get(commit.url, None) if commit.url else None
            if pr and pr.auto_merge_status == "ENABLED":
                prev_commit = commits_old_to_new[i - 1]
                prev_pr = (
                    prs_by_url.get(prev_commit.url, None) if prev_commit.url else None
                )
                if not prev_pr or prev_pr.head_branch != pr.base_branch:
                    raise UserException(
                        f"PR {pr.url} is auto-mergeable.\n"
                        + "I can't update it at GitHub without risking to auto-merge to a wrong branch.\n"
                        + "Please disable auto-merge for the PR and try again."
                    )

    #
    # Starting from commit with hash earliest_hash which has no PR URL in the
    # description, creates the missing PRs and updates commits descriptions with
    # the returned URL.
    #
    def process_create_missing_prs_in_rebase_interactive(
        self,
        *,
        earliest_hash: str,
        commits: list[Commit],
    ):
        try:
            commits_to_rebase = list(
                dropwhile(lambda c: c.hash != earliest_hash, reversed(commits))
            )
            assert (
                commits_to_rebase
            ), f"earliest_hash={earliest_hash} must be in commits={commits}"
            cmd = shlex.join(
                [
                    __file__,
                    *(["--debug"] if self.debug else []),
                    *(
                        ["--debug-force-push-branches"]
                        if self.debug_force_push_branches
                        else []
                    ),
                ]
            )
            todo = "".join(
                [
                    f"pick {c.hash} {c.title}\n"
                    + f"exec {INTERNAL_IN_REBASE_INTERACTIVE_VAR}="
                    + shlex.quote(
                        InRebaseInteractiveData(
                            commit_index_one_based=(
                                len(commits) - len(commits_to_rebase) + i + 1
                            ),
                            total_commits_in_stack=len(commits),
                        ).stringify()
                    )
                    + f" {cmd}\n"
                    for [i, c] in enumerate(commits_to_rebase)
                ]
            )
            self.git_rebase_interactive_exec(
                earliest_hash=earliest_hash,
                skip_res=[
                    r"^You can fix the problem, and then run$",
                    r"^\s*git rebase --continue$",
                ],
                todo=f"\n{todo}",
            )
        except (CalledProcessError, KeyboardInterrupt) as e:
            self.shell_no_throw(["git", "rebase", "--abort"])
            raise e

    #
    # Iterates over the list of commits with URLs and pushes their branches to
    # update the corresponding PRs.
    #
    def process_update_existing_prs_from_commits_with_urls(
        self,
        *,
        commits: list[Commit],
        commit_hashes_to_push_branch: list[str],
    ):
        # We must iterate from the oldest commit to the newest one, because
        # previous commit PR's branch becomes the next commit PR's base branch.
        commits_old_to_new = list(reversed(commits))

        # Collect commits/branches that need to be pushed.
        to_push: dict[str, Branch] = {}
        for commit in commits_old_to_new:
            if (
                self.debug_force_push_branches
                or commit.hash in commit_hashes_to_push_branch
            ):
                commit.branch = self.process_commit_infer_branch(commit=commit)
                to_push[commit.branch] = Branch(hash=commit.hash, branch=commit.branch)

        push_results = {}
        if to_push and self.git_commits_were_not_reordered(commits=commits):
            self.print_header(
                f"Pushing {len(to_push)} PR head{'s' if len(to_push) > 1 else ''} atomically:"
            )
            push_results = self.git_push_branches(branches=[*to_push.values()])
            for branch, result in push_results.items():
                self.print_branch_result(
                    type="head",
                    branch=branch,
                    result=result,
                )

        for i, commit in enumerate(commits_old_to_new):
            self.print_header(f"Updating PR: {self.clean_title(commit.title)}")

            # If we did not push this branch yet (e.g. because the commits were
            # reordered), push the branches sequentially, interleaving the
            # pushes with PR updates. This minimizes the chance that GitHub will
            # close some of PRs or mark them as merged in case of commits
            # reordering (but it still may happen rarely, just unlikely).
            if commit.branch in to_push and commit.branch not in push_results:
                push_results.update(
                    self.git_push_branches(branches=[to_push[commit.branch]])
                )
                result = push_results[commit.branch]
                if result == "pushed":
                    self.print_branch_result(
                        type="head",
                        branch=str(commit.branch),
                        result=result,
                    )

            pr, result = self.process_update_pr(
                prev_commit=commits_old_to_new[i - 1] if i > 0 else None,
                commit=commit,
                commits=commits,
            )
            self.print_pr_result(
                url=pr.url,
                result=result,
                review_decision=pr.review_decision,
            )
            commits_old_to_new[i].branch = pr.head_branch

    #
    # For a commit, infers its corresponding remote branch name by either
    # querying it from the PR (when commit.url is set), or by building it from
    # the commit title and hash.
    #
    def process_commit_infer_branch(
        self,
        *,
        commit: Commit,
    ) -> str:
        if commit.url:
            pr = self.gh_get_pr(url=commit.url)  # likely a cache hit
            return pr.head_branch
        else:
            return self.build_branch_name(
                title=commit.title,
                commit_hash=commit.hash,
            )

    #
    # Updates PR fields:
    # - base branch (in case the commits were reordered, or some of them were
    #   merged into the remote, so the the beginning of the stack started
    #   pointing not to a branch, but to a remote tip)
    # - full stack list in the description
    # - git-grok related labels
    #
    # It's BTW not possible to update the head branch once PR is created.
    #
    def process_update_pr(
        self,
        *,
        prev_commit: Commit | None,
        commit: Commit,
        commits: list[Commit],
    ) -> tuple[Pr, PrUpsertResult]:
        pr_numbers: list[int] = []
        pr_number_current: int | None = None
        for c in commits:
            assert c.url is not None
            if m := re.search(r"/(\d+)$", c.url):
                pr_numbers.append(int(m.group(1)))
                if c.hash == commit.hash:
                    pr_number_current = int(m.group(1))
        assert commit.url is not None
        return self.gh_update_pr(
            url=commit.url,
            base_branch=prev_commit.branch if prev_commit else None,
            head_commit_hash=commit.hash,
            pr_numbers=pr_numbers,
            pr_number_current=pr_number_current,
        )

    #
    # Verifies that the gh supports e.g. autoMergeRequest field.
    #
    def gh_verify_version(self):
        out = self.shell(["gh", "--version"])
        if not (m := re.search(r"(version\s+|v)(\d+(\.\d+)+)", out)) or parse_version(
            m.group(2)
        ) < parse_version(GH_MIN_VERSION):
            raise UserException(
                f"The tool requires gh version {GH_MIN_VERSION} or higher; please upgrade. Got:\n{out.strip()}"
            )

    #
    # Returns current GitHub login.
    #
    def gh_get_current_login(self) -> str:
        return self.shell(["gh", "api", "user", "--jq", ".login"])

    #
    # Verifies Git version.
    #
    def git_verify_version(self):
        self.shell_no_throw(["git", "--version"])

    #
    # Returns current git folder remote (most often "origin").
    #
    def git_get_current_remote(self) -> str:
        [_, symbolic_ref, _] = self.shell_no_throw(
            ["git", "symbolic-ref", "-q", "HEAD"]
        )
        if not symbolic_ref:
            raise UserException(
                'To run git-grok, you must be on a branch. Check your "git status".'
            )
        push_short = self.shell(
            ["git", "for-each-ref", "--format=%(push:short)", symbolic_ref]
        )
        if not (m := re.match(r"^([^/]+)/.+$", push_short)):
            raise UserException(
                f'fatal: No configured push destination for symbolic ref "{symbolic_ref}".\n'
                + "\n"
                + "Git infers the current remote from the branch name using one of the following ways:\n"
                + '1. It checks whether "git config branch.<branch>.remote" is set explicitly.\n'
                + '2. Or, if "git config push.default" is "current" or "matching", there must be\n'
                + "   only one remote configured.\n"
            )
        return m.group(1)

    #
    # Returns the current remote branch name on GitHub.
    #
    def git_get_current_remote_base_branch(self) -> str:
        branch = self.shell(["git", "branch", "--show-current"])
        if not branch:
            path = ".git/rebase-merge/head-name"
            if file := find_file_in_parents(path):
                branch = open(file).readline().strip()
                if not (m := re.match(r"refs/heads/(.+)", branch)):
                    raise UserException(f"File {path} doesn't contain refs/heads/*")
                branch = m.group(1)
            else:
                raise UserException(
                    f"You must be on a branch or in an interactive rebase mode."
                )
        return branch

    #
    # Returns current git folder owner name and repository name.
    #
    def gh_get_current_repo_owner_and_name(self) -> tuple[str, str]:
        out_str = self.shell(
            [
                "gh",
                "repo",
                "view",
                "--json",
                "owner,name",
                "--jq",
                "[.owner.login,.name]",
            ]
        )
        return tuple(json.loads(out_str))

    #
    # Pre-creates git-grok related labels.
    #
    def gh_upsert_labels(self):
        try:
            self.shell(
                [
                    "gh",
                    "label",
                    "create",
                    MIDDLE_PR_LABEL,
                    "-d",
                    MIDDLE_PR_LABEL_DESCRIPTION,
                    "-c",
                    MIDDLE_PR_LABEL_COLOR,
                ],
            )
            # It's faster to ignore the "already exists" error than to use
            # --force flag.
        except CalledProcessError as e:
            if "already exists" not in e.stderr:
                raise

    #
    # Creates a GitHub PR between two existing branches. The description of the
    # new PR will NOT include the body suffix with the list of all PRs in the
    # stack, since we don't know all URLs in this list yet.
    #
    def gh_create_pr(
        self,
        *,
        base_branch: str | None,
        head_branch: str,
        title: str,
        body: str | None,
        is_middle_pr: bool,
    ) -> tuple[str, PrUpsertResult]:
        if not base_branch:
            base_branch = self.remote_base_branch

        if body is not None:
            body_file = TMP_BODY_FILE
            with open(body_file, "w+") as file:
                file.write(body)
        else:
            body_file = find_file_in_parents(".github/pull_request_template.md")

        cmd = [
            "gh",
            "pr",
            "create",
            "--base",
            base_branch,
            "--head",
            head_branch,
            *(["--label", MIDDLE_PR_LABEL] if is_middle_pr else []),
            "--title",
            title,
            *(["--body-file", body_file] if body_file else ["--body", ""]),
        ]

        attempt = 0
        while True:
            returncode, output, stderr = self.shell_no_throw(cmd)
            if returncode == 0:
                return output, "created"

            if m := re.match(r".* already exists[^\n]\n(\S+)", stderr, flags=re.S):
                return m.group(1), "up-to-date"

            if attempt < 3 and (
                m := re.match(r".* was submitted too quickly", stderr, flags=re.S)
            ):
                dt = 3 + random.random() * 3
                self.debug_log_text(text=f"Waiting for {dt} seconds and retrying...")
                sleep(dt)
                attempt += 1
                continue

            raise CalledProcessError(
                returncode=returncode,
                cmd=cmd,
                output=output,
                stderr=stderr,
            )

    #
    # Updates base_branch and description suffix of the PR.
    #
    def gh_update_pr(
        self,
        *,
        url: str,
        base_branch: str | None,
        head_commit_hash: str,
        pr_numbers: list[int],
        pr_number_current: int | None,
    ) -> tuple[Pr, PrUpsertResult]:
        if base_branch is None:
            base_branch = self.remote_base_branch

        pr = self.gh_get_pr(url=url)
        new_body = body_suffix_upsert(pr.body, pr_numbers, pr_number_current)
        is_middle_pr = len(pr_numbers) > 0 and pr.number not in (
            pr_numbers[0],
            pr_numbers[-1],
        )

        if (
            pr.base_branch == base_branch
            and pr.body == new_body
            and pr.state == "OPEN"
            and (MIDDLE_PR_LABEL in pr.labels) == is_middle_pr
        ):
            return pr, "up-to-date"

        self.cache_clean(url)

        upsert_result = "updated"

        if pr.state != "OPEN":
            upsert_result = "reopened"
            returncode, output, stderr = self.shell_no_throw(
                cmd := [
                    "gh",
                    "pr",
                    "reopen",
                    url,
                    "--comment",
                    "Reopened by git-grok.",
                ],
            )
            if (
                returncode != 0
                and len(pr.commit_hashes) > 0
                and "Could not open the pull request" in stderr
            ):
                # https://github.com/isaacs/github/issues/361 - "The XXX branch
                # was force pushed or recreated". "We're blocking the pull
                # request reopen if the current head isn't a descendant of the
                # stored head sha (which is what the head was when the pull
                # request was closed). We are not allowing the reopen in that
                # case, because there is no good way to tell what changes have
                # happened while a pull request was closed and the head branch
                # has changed."
                self.print_pr_closed_and_has_bad_head_branch()
                temp_commit_hash = pr.commit_hashes[-1]
                self.git_push_branches(
                    branches=[Branch(hash=temp_commit_hash, branch=pr.head_branch)]
                )
                sleep(5)  # GitHub replication lag?
                self.shell(
                    [
                        "gh",
                        "pr",
                        "reopen",
                        url,
                        "--comment",
                        f"Hack: temporarily force-pushing the old commit {temp_commit_hash} to the head branch {pr.head_branch} and reopening by git-grok. "
                        + "See https://github.com/isaacs/github/issues/361 for details.",
                    ],
                )
                self.git_push_branches(
                    branches=[Branch(hash=head_commit_hash, branch=pr.head_branch)]
                )
            elif returncode != 0:
                raise CalledProcessError(
                    returncode=returncode,
                    cmd=cmd,
                    output=output,
                    stderr=stderr,
                )
        self.shell(
            [
                "gh",
                "pr",
                "edit",
                url,
                "--base",
                base_branch,
                *(
                    ["--add-label", MIDDLE_PR_LABEL]
                    if is_middle_pr and MIDDLE_PR_LABEL not in pr.labels
                    else (
                        ["--remove-label", MIDDLE_PR_LABEL]
                        if not is_middle_pr and MIDDLE_PR_LABEL in pr.labels
                        else []
                    )
                ),
                "--body-file",
                "-",
            ],
            input=new_body,
        )

        pr.base_branch = base_branch
        pr.body = new_body
        return pr, upsert_result

    #
    # Reads PR info from GitHub.
    #
    # We read PRs one by one and not in GraphQL-bulk for 3 reasons:
    # - Granular caching. We use cache_through() for each PR, so in the
    #   consequent interactive rebase call, it will be reused (and also, it will
    #   be reused in other places where we need to read a PR info).
    # - It is not much worse in performance, because we run the initial
    #   gh_get_pr() in parallel, in Task threads.
    # - Simplicity reason: we want to avoid GraphQL code duplication with the
    #   logic of gh_get_pr().
    #
    def gh_get_pr(self, *, url: str) -> Pr:
        out_str = self.cache_through(
            url,
            lambda: self.shell(
                [
                    "gh",
                    "pr",
                    "view",
                    url,
                    "--json",
                    "number,title,body,baseRefName,headRefName,url,reviewDecision,state,labels,autoMergeRequest,commits",
                ],
            ),
        )
        value = json.loads(out_str)
        return Pr(
            number=int(value["number"]),
            title=value["title"],
            body=value["body"],
            base_branch=re.sub(r"^refs/heads/", "", value["baseRefName"]),
            head_branch=re.sub(r"^refs/heads/", "", value["headRefName"]),
            url=value["url"],
            review_decision=value["reviewDecision"],
            state=value["state"],
            auto_merge_status="ENABLED" if value["autoMergeRequest"] else "DISABLED",
            labels=[label["name"] for label in value["labels"]],
            commit_hashes=[c["oid"] for c in value["commits"]],
        )

    #
    # Returns parsed commits between two refs in reverse-chronological order
    # (newest commits first, oldest last, as they're shown in "git log").
    #
    # The returned commits will have branch = None, since it's unknown yet.
    #
    def git_get_commits(
        self,
        *,
        latest_ref: str | None = None,
        earliest_ref: str | None = None,
        count_back_in_time: int | None = None,
    ) -> list[Commit]:
        if latest_ref is None:
            latest_ref = "HEAD"
        if earliest_ref is None:
            earliest_ref = f"remotes/{self.remote}/{self.remote_base_branch}"
        if count_back_in_time:
            out = self.shell(["git", "log", latest_ref, f"-{count_back_in_time}"])
        else:
            out = self.shell(["git", "log", f"{earliest_ref}..{latest_ref}"])
        commits: list[Commit] = []
        for commit in re.split(r"^(?=commit )", out, flags=re.M)[1:]:
            try:
                if not (
                    m := re.match(
                        r"commit (\w+)[^\n]*\n(.*?)\n\n(.*)$", commit, flags=re.S
                    )
                ):
                    raise UserException("Can't parse commit-headers-body.")

                hash, _headers, body = m.group(1), m.group(2), m.group(3).rstrip()

                if not (m := re.match(r"([^\n]+)\n?(.*)$", body, flags=re.S)):
                    raise UserException(f"Can't extract commit title and description.")
                title, description = m.group(1).strip(), m.group(2)

                m = re.search(PR_HEADER_RE, description, flags=re.M)
                url = m.group(1).strip() if m else None
                expected_base_branch = m.group(2).strip() if m and m.group(2) else None

                # People often times cherry-pick commits from one branch to
                # another to e.g. ship hot-fixes in production or staging
                # branch. In this case, we must ignore the PR URL, because along
                # with this cherry-pick, the commit message (with existing PR
                # URL) is copied, so we don't want to have a collision.
                if (
                    expected_base_branch is not None
                    and expected_base_branch != self.remote_base_branch
                ):
                    url = None
            except UserException as e:
                raise UserException(f"{str(e)} Commit:\n<<<\n{commit.strip()}\n>>")
            except BaseException as e:
                tb = traceback.format_exc()
                raise UserException(f"{tb}\nCommit:\n<<<\n{commit.strip()}\n>>\n\n")

            commits.append(
                Commit(
                    hash=hash,
                    url=url,
                    title=title,
                    description=description,
                    branch=None,
                )
            )
        return commits

    #
    # Pushes multiple branches atomically to remote GitHub. Returns a dict
    # mapping branch names to their push results.
    #
    def git_push_branches(
        self,
        *,
        branches: list[Branch],
    ) -> dict[str, BranchPushResult]:
        if not branches:
            return {}
        # Git push is a quick no-op on GitHub end if the branch isn't changed
        # (it prints "Everything up-to-date"), so we always push and then verify
        # the output for the status (instead of fetching from the remote and
        # comparing the branch'es tip commit hash).
        out = self.shell(
            [
                "git",
                "push",
                "-f",
                self.remote,
                *[f"{branch.hash}:refs/heads/{branch.branch}" for branch in branches],
            ],
            stderr_to_stdout=True,
        )
        # If the hash is NOT mentioned in the output, it's either a short
        # "Everything up-to-date" message (which means that ALL branches are
        # unchanged), or THIS particular branch is up-to-date. I.e. if a branch
        # is changed, git always prints its hash in the output, on one of the
        # following formats:
        # 1. * [new branch] 10dc4f6 -> grok/...
        # 2. + 10dc4f6...b28d03e 10dc4f6 -> grok/... (forced update)
        results: dict[str, BranchPushResult] = {
            branch.branch: "up-to-date" for branch in branches
        }
        for branch in branches:
            for line in out.splitlines():
                if branch.hash in line:
                    results[branch.branch] = "pushed"
                    break
        return results

    #
    # Assigns the provided commit hash to the remote branch without pushing it.
    # This is useful after e.g. changing the commit message.
    #
    def git_assign_branch_to_hash(self, *, branch: str, hash: str):
        self.shell(
            [
                "git",
                "update-ref",
                f"refs/remotes/{self.remote}/{branch}",
                f"{hash}",
            ],
        )

    #
    # Runs an interactive rebase with the provided shell command.
    #
    def git_rebase_interactive_exec(
        self,
        *,
        earliest_hash: str,
        skip_res: list[str] = [],
        todo: str,
    ):
        self.shell_passthrough(
            [
                "git",
                "rebase",
                "--quiet",
                "--interactive",
                f"{earliest_hash}^",
            ],
            env={"GIT_SEQUENCE_EDITOR": f"echo {shlex.quote(todo)} >"},
            skip_res=[r"Executing: ", *skip_res],
        )

    #
    # Updates the message suffix (pointing to a PR URL) of the current commit
    # which is at the moment selected (activated) with interactive rebase.
    #
    def git_update_current_commit_message(
        self,
        *,
        header_name: str,
        header_value: str,
        header_comment: str | None = None,
    ) -> CommitUpdateResult:
        new_header = f"{header_name}: {header_value}"
        if header_comment:
            new_header += f" ({header_comment})"
        message = self.shell(
            ["git", "show", "--pretty=format:%B", "--no-patch"],
            no_rstrip=True,
        )
        if m := re.search(rf"^{header_name}: [^\n]+", message, flags=re.M):
            new_message = message.replace(m[0], new_header)
        else:
            new_message = f"{message.rstrip()}\n\n{new_header}"
        if new_message != message:
            self.shell(
                ["git", "commit", "--amend", "--no-verify", "-F", "-"],
                input=new_message,
            )
            return "updated"
        else:
            return "up-to-date"

    #
    # Checks whether the order of the commits on top of the upstream remained
    # the same since the last run. If so, we are e.g. allowed to push multiple
    # branches in bulk, atomically.
    #
    def git_commits_were_not_reordered(self, *, commits: list[Commit]) -> bool:
        latest_commit_branch = self.process_commit_infer_branch(commit=commits[0])
        remote_commits = self.git_get_commits(
            latest_ref=f"remotes/{self.remote}/{latest_commit_branch}",
        )
        commit_urls = [c.url for c in commits]
        remote_commit_urls = [c.url for c in remote_commits]
        self.debug_log_text(
            text=f"Local URLs:  {str(commit_urls)}\n"
            + f"Remote URLs: {str(remote_commit_urls)}"
        )
        return commit_urls == remote_commit_urls

    #
    # Runs a shell command returning results.
    #
    def shell(
        self,
        cmd: list[str],
        *,
        no_rstrip: bool = False,
        input: str | None = None,
        stderr_to_stdout: bool = False,
        env: dict[str, str] | None = None,
        comment: str | None = None,
    ) -> str:
        out = None
        returncode = 0
        time_start = time()
        try:
            out = check_output(
                cmd,
                text=True,
                stderr=subprocess.STDOUT if stderr_to_stdout else subprocess.PIPE,
                input=input,
                env={**os.environ, **env} if env else None,
            )
            return out if no_rstrip else out.rstrip()
        except CalledProcessError as e:
            returncode = e.returncode
            out = "\n".join(s for s in [e.stdout, e.stderr] if s)
            raise
        finally:
            self.debug_log_shell_command(
                cmd=cmd,
                env=env,
                out=out,
                took_s=time() - time_start,
                returncode=returncode,
                comment=comment,
            )

    #
    # Same as shell(), but never throws and returns an exit code along with the
    # outputs instead.
    #
    def shell_no_throw(
        self,
        cmd: list[str],
        *,
        no_rstrip: bool = False,
        env: dict[str, str] | None = None,
        comment: str | None = None,
    ) -> tuple[int, str, str]:
        stdout = ""
        stderr = ""
        returncode = None
        time_start = time()
        try:
            proc = Popen(
                cmd,
                text=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                env={**os.environ, **env} if env else None,
            )
            stdout, stderr = proc.communicate()
            if not no_rstrip:
                stdout = stdout.rstrip()
                stderr = stderr.rstrip()
            returncode = proc.returncode
            return (
                proc.returncode,
                stdout,
                stderr,
            )
        finally:
            self.debug_log_shell_command(
                cmd=cmd,
                env=env,
                out="\n".join(s for s in [stdout, stderr] if s),
                took_s=time() - time_start,
                returncode=returncode,
                comment=comment,
            )

    #
    # Runs a shell command, but prints its output as is.
    #
    def shell_passthrough(
        self,
        cmd: list[str],
        *,
        env: dict[str, str] | None = None,
        skip_res: list[str] = [],
        comment: str | None = None,
    ):
        out = ""
        self.debug_log_shell_command(
            cmd=cmd,
            env=env,
            out="",
            took_s=0,
            returncode=None,
            comment=comment,
        )
        with Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,  # to apply skip_res to stderr as well
            text=True,
            bufsize=1,
            env={**os.environ, **env} if env else None,
        ) as pipe:
            assert pipe.stdout is not None
            for line in pipe.stdout:
                line = line.rstrip()
                if not line:
                    continue
                out += line + "\n"
                if not any(re.search(r, line, flags=re.S) for r in skip_res):
                    print(line)
                    sys.stdout.flush()
            returncode = pipe.wait()
            if returncode != 0:
                raise CalledProcessError(returncode=returncode, cmd=cmd)

    #
    # Tries to self-update the tool by pulling from git.
    #
    def self_update(self):
        dir = os.path.dirname(os.path.realpath(__file__))
        if not os.path.exists(f"{dir}/.git"):
            return
        self.shell_no_throw(
            ["sh", "-c", f"cd {shlex.quote(dir)} && git pull --rebase"],
            comment="self-update",
        )

    #
    # Cleans a title from useless prefix/suffix.
    #
    def clean_title(self, title: str) -> str:
        title = title.strip()
        title = re.sub(r"^\w+[()\[\]\w]*:\s+", "", title)
        title = re.sub(r"\[[-\w]+\]$", "", title)
        title = title.strip()
        max_len = max(
            MIN_TITLE_LEN_IN_PRINT,
            TERMINAL_SIZE.columns - 22,
        )
        if len(title) > max_len:
            title = title[0:max_len] + "…"
        return title

    #
    # Builds branch name from commit title.
    #
    def build_branch_name(self, *, title: str, commit_hash: str) -> str:
        branch = title
        branch = branch.strip()
        branch = re.sub(r"\[[-\w]+\]$", "", branch)
        branch = branch.lower()
        branch = re.sub(r"^\W+|\W+$", "", branch)
        branch = re.sub(r"\W+", "-", branch)
        branch += f"-to-{self.remote_base_branch}-{commit_hash[0:4]}"
        return f"{BRANCH_PREFIX}{self.login}/{branch}"

    #
    # Prints a status after a branch push attempt happened.
    #
    def print_branch_result(
        self,
        *,
        type: BranchType,
        branch: str,
        result: BranchPushResult,
    ):
        max_len = max(
            MIN_BRANCH_LEN_IN_PRINT,
            TERMINAL_SIZE.columns - (11 + 4 + len(self.remote) + 10) - 5,
        )
        if len(branch) > max_len:
            branch = branch[0:max_len] + "…"
        print(f"  ── {type}: {self.remote}/{branch} ({result})")
        sys.stdout.flush()

    #
    # Prints a "PR created" message.
    #
    def print_pr_created(self, *, comment: str | None = None):
        # ATTENTION: we DO NOT print the newly created PR URL here, because it
        # lacks the footer with links to all other PRs in the stack yet. If
        # someone starts editing it before that footer is added (later, during
        # the next stage), then they'll risk to lose the text! So we have no
        # choice but to force the user to wait.
        print(f"  ── new Pull Request created" + (f" ({comment})" if comment else ""))
        sys.stdout.flush()

    #
    # Prints a "PR has bad branch" message.
    #
    def print_pr_closed_and_has_bad_head_branch(self):
        print(f"  🧟 this closed PR has a bad head branch, so trying a hack")
        sys.stdout.flush()

    #
    # Prints a "PR cannot be opened" message.
    #
    def print_pr_closed_and_non_openable_no_commits(self):
        print(
            f"  💀 this closed PR has 0 commits and cannot be reopened, so recreating"
        )
        sys.stdout.flush()

    #
    # Prints a "PR was accidentally merged" message.
    #
    def print_pr_accidentally_merged(self):
        print(f"  💀 this PR was accidentally merged into {BRANCH_PREFIX}*, recreating")
        sys.stdout.flush()

    #
    # Prints a status after a commit message was updated locally.
    #
    def print_commit_message_updated(self):
        print(f"  ── added PR URL to commit's message to bind them")
        sys.stdout.flush()

    #
    # Prints a status after a PR was created/updated on GitHub.
    #
    def print_pr_result(
        self,
        *,
        url: str,
        result: PrUpsertResult,
        review_decision: PrReviewDecision,
    ):
        icon = (
            review_decision == "APPROVED"
            and "🟢"
            or review_decision == "CHANGES_REQUESTED"
            and "🔴"
            or "🟡"
        )
        print(f"  {icon} {url} ({result})")
        sys.stdout.flush()

    #
    # Prints the heading message of an operation.
    #
    def print_header(self, header: str):
        print(header)
        sys.stdout.flush()

    #
    # Logs the current command line arguments.
    #
    def debug_log_argv(self):
        text = shlex.join(sys.argv).strip()
        for var in [INTERNAL_IN_REBASE_INTERACTIVE_VAR, INTERNAL_SKIP_UPDATE_PRS_VAR]:
            value = os.environ.get(var)
            if value:
                text = f"{var}={shlex.quote(value)} {text}"
        self.debug_log_text(text=text)

    #
    # Logs a list of commits and their corresponding PR statuses.
    #
    def debug_log_commits(
        self,
        *,
        commits: list[Commit],
        prs_by_url: dict[str, Pr],
    ):
        max_url_len = max(
            [len(c.url) for c in commits if c.url],
            default=0,
        )
        max_state_len = max(
            [len(pr.state) for pr in prs_by_url.values()],
            default=0,
        )
        max_head_branch_len = max(
            [len(pr.head_branch) for pr in prs_by_url.values()],
            default=0,
        )
        lines: list[str] = []
        for c in commits:
            url = c.url or "-"
            pr = prs_by_url.get(url)
            state = pr.state if pr else "-"
            head_branch = pr.head_branch if pr else "-"
            lines.append(
                f"{c.hash} | {url.ljust(max_url_len)} | {head_branch.ljust(max_head_branch_len)} | {state.ljust(max_state_len)} | {c.title}"
            )
        self.debug_log_text(text="\n".join(lines))

    #
    # Logs a command which is run by the tool.
    #
    def debug_log_shell_command(
        self,
        *,
        cmd: list[str],
        env: dict[str, str] | None,
        out: str | None,
        took_s: float,
        returncode: int | None,
        comment: str | None = None,
    ):
        rows: list[tuple[tuple[int, int, int], str]] = []
        rows.append(
            (
                DEBUG_COLOR_GRAY_1,
                "$ "
                + (
                    " ".join([f"{k}={shlex.quote(v)}" for (k, v) in env.items()]) + " "
                    if env
                    else ""
                )
                + shlex.join(cmd).strip()
                + (f" # took {int(took_s * 1000)} ms" if took_s else "")
                + (f" # returncode={returncode}" if returncode else "")
                + (
                    f" # ran in a parallel thread"
                    if current_thread() is not main_thread()
                    else ""
                )
                + (f" # {comment}" if comment else ""),
            )
        )
        if out:
            rows.append(
                (
                    DEBUG_COLOR_GRAY_2,
                    re.sub(
                        r"^",
                        "  ",
                        re.sub(r"\n([| \t]*\n)+", "\n", out.rstrip()),
                        flags=re.M,
                    ),
                )
            )

        if os.environ.get(INTERNAL_IN_REBASE_INTERACTIVE_VAR):
            rows = [(row[0], re.sub(r"^", "> ", row[1], flags=re.M)) for row in rows]

        self.debug_log_text(text="\n".join(row[1] for row in rows))
        if self.debug:
            for row in rows:
                print(colored(*row[0], row[1]))
            sys.stdout.flush()

    #
    # Logs a text block (prepended by date) to the debug file.
    #
    def debug_log_text(self, *, text: str):
        try:
            with open(DEBUG_FILE, "a+") as file:
                file.write(
                    f"=== {datetime.now()}"
                    + (
                        f" (in rebase interactive, {self.in_rebase_interactive.commit_index_one_based}/{self.in_rebase_interactive.total_commits_in_stack})"
                        if self.in_rebase_interactive
                        else ""
                    )
                    + "\n"
                )
                file.write(f"{text.rstrip()}\n")
                file.write("\n")
        except:
            pass

    #
    # Caches the return value of a function in environment and returns it next time
    # it's requested.
    #
    def cache_through(self, key: str, func: Callable[[], str]) -> str:
        key = hashify(key)
        var = f"{INTERNAL_ENV_VAR_PREFIX}_{key}"
        value = os.environ.get(var)
        if value is None:
            value = func()
            os.environ[var] = value
        else:
            self.debug_log_shell_command(
                cmd=["printenv", var],
                env=None,
                out=value,
                took_s=0,
                returncode=None,
                comment="cache hit",
            )
        return value

    #
    # Removes the cached value for the key.
    #
    def cache_clean(self, key: str):
        key = hashify(key)
        var = f"{INTERNAL_ENV_VAR_PREFIX}_{key}"
        os.environ.pop(var, None)


#
# Splits a list into chunks of size n.
#
def chunk(lst: list[T], n: int) -> list[list[T]]:
    res: list[list[T]] = []
    for i in range(0, len(lst), n):
        res.append(lst[i : i + n])
    return res


#
# Returns a colored text.
#
def colored(r: int, g: int, b: int, text: str) -> str:
    return f"\033[38;2;{r};{g};{b}m{text}\033[0m"


#
# Traverse the filesystem from the current directory to root trying to find a
# matching relative file path in parent directories.
#
def find_file_in_parents(file: str) -> str | None:
    path = os.getcwd()
    old_path = ""
    while old_path != path:
        full = os.path.join(path, file)
        if os.path.exists(full):
            return full
        old_path = path
        path = os.path.dirname(path)
    return None


#
# If there is no body suffix in the body, appends it. Otherwise, replaces the
# previous occurrence of the body suffix (heuristically found) with the new one.
#
def body_suffix_upsert(
    body: str,
    pr_numbers: list[int],
    pr_number_current: int | None,
) -> str:
    items = [
        f"- {'➡ ' if pr_number == pr_number_current else ''}#{pr_number}"
        for pr_number in pr_numbers
    ]
    suffix = (
        BODY_SUFFIX_TITLE + "\n" + "\n".join(items) + "\n\n" + BODY_SUFFIX_FOOTER + "\n"
    )
    if re.search(BODY_SUFFIX_RE, body, flags=re.M | re.I | re.X):
        return re.sub(BODY_SUFFIX_RE, suffix, body, flags=re.M | re.I | re.X)
    return body.rstrip() + "\n\n" + suffix


#
# Hashes a text, but keeps it recognizable. Seems like in some shells, we can't
# have env variables with arbitrary characters, so we have to normalize
# (otherwise, some tests fail in GitHub Actions).
#
def hashify(text: str) -> str:
    return (
        re.sub(r"^_+|_+$", "", re.sub(r"[^A-Za-z0-9]+", "_", text))
        + "_"
        + hashlib.sha256(text.encode()).hexdigest()[0:8]
    )


#
# Parses a version string into a tuple of integers.
#
def parse_version(v: str) -> tuple[int, ...]:
    return tuple(map(int, (v.split("."))))


#
# Runs a function in a separate thread. To wait for its termination and get its
# return value, call wait() method. If the function raises an exception, it will
# be re-raised in the calling thread.
#
class Task(Generic[T]):
    _result: T
    _error: BaseException | None = None
    _thread: Thread

    def __init__(self, target: Callable[..., T], *args: ..., **kwargs: ...):
        def target_wrapper():
            try:
                self._result = target(*args, **kwargs)
            except BaseException as e:
                self._error = e

        self._thread = Thread(target=target_wrapper)
        self._thread.start()

    def wait(self) -> T:
        self._thread.join()
        if self._error:
            raise self._error
        return self._result


#
# If raised, the stacktrace is not shown.
#
class UserException(Exception):
    pass


if __name__ == "__main__":
    try:
        sys.exit(Main().run())
    except KeyboardInterrupt:
        signal.signal(signal.SIGINT, signal.SIG_DFL)
        os.kill(os.getpid(), signal.SIGINT)
    except UserException as e:
        print(re.sub(r"^", "❌ ", str(e), flags=re.M))
        sys.exit(1)
    except CalledProcessError as e:
        print(
            f'Command "{shlex.join(e.cmd)}" returned status {e.returncode}.'
            + (f"\n{e.stdout}" if e.stdout else "")
            + (f"\n{e.stderr}" if e.stderr else ""),
            file=sys.stderr,
        )
        sys.exit(2)
