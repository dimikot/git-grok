#!/usr/bin/env python3
from __future__ import annotations
import argparse
import hashlib
import json
import os
import random
import re
import shlex
import subprocess
import sys
import traceback
from dataclasses import dataclass
from datetime import datetime
from itertools import dropwhile
from subprocess import CalledProcessError, Popen, check_output
from threading import Thread, current_thread, main_thread
from time import time, sleep
from typing import Callable, Literal, TypeVar, Generic

BRANCH_PREFIX = "grok/"
PR_HEADER = "Pull Request"
PR_HEADER_RE = rf"^\s+{PR_HEADER}: (https://\S+)(?: \((.*?)\))?"
MIDDLE_PR_LABEL = "git-grok-middle-pr"
MIDDLE_PR_LABEL_DESCRIPTION = "This PR is in the middle of the stack."
MIDDLE_PR_LABEL_COLOR = "CCCCCC"
BODY_SUFFIX_TITLE = "## PRs in the Stack"
BODY_SUFFIX_FOOTER = (
    "(The stack is managed by [git-grok](https://github.com/dimikot/git-grok).)"
)
BODY_SUFFIX_RE = (
    rf"^ {re.escape(BODY_SUFFIX_TITLE)} [^\n]* \n"
    + r"( (\s*(\n|\Z))* (- \s* [^\n]+ (\n|\Z)) )*"
    + r"( (\s*(\n|\Z))* [^\n]+ \bgit-grok\b [^\n]+ (\n|\Z) )?"
)
MIN_BRANCH_LEN_IN_PRINT = 36
MIN_TITLE_LEN_IN_PRINT = 36
TMP_BODY_FILE = "/tmp/git-grok.body"
INTERNAL_ENV_VAR_PREFIX = "GIT_GROK"
INTERNAL_IN_REBASE_INTERACTIVE_VAR = f"{INTERNAL_ENV_VAR_PREFIX}_in_rebase_interactive"
INTERNAL_SKIP_UPDATE_PRS_VAR = f"{INTERNAL_ENV_VAR_PREFIX}_skip_update_prs"
DEBUG_FILE = "/tmp/git-grok.log"
DEBUG_COLOR_GRAY_1 = (128, 128, 128)
DEBUG_COLOR_GRAY_2 = (92, 92, 92)

try:
    TERMINAL_SIZE = os.get_terminal_size()
    os.environ["COLUMNS"] = str(TERMINAL_SIZE.columns)
    os.environ["LINES"] = str(TERMINAL_SIZE.lines)
except:
    TERMINAL_SIZE = os.terminal_size(  # type: ignore
        (
            int(os.environ.get("COLUMNS", "512")),
            int(os.environ.get("LINES", "40")),
        )
    )


#
# A parsed commit from the local git folder.
#
@dataclass
class Commit:
    hash: str
    url: str | None
    title: str
    description: str
    branch: str | None


#
# A parsed remote PR loaded from GitHub.
#
@dataclass
class Pr:
    number: int
    title: str
    body: str
    base_branch: str
    head_branch: str
    url: str
    review_decision: PrReviewDecision
    state: Literal["OPEN", "CLOSED", "MERGED"]
    auto_merge_status: Literal["ENABLED", "DISABLED"]
    labels: list[str]


#
# Some data passed from the main process to each individual child process call
# within "git rebase -i", for each commit in the stack.
#
@dataclass
class InRebaseInteractiveData:
    commit_index_one_based: int
    total_commits_in_stack: int

    @staticmethod
    def parse(str: str) -> InRebaseInteractiveData | None:
        if m := re.match(r"^(\d+)/(\d+)$", str):
            return InRebaseInteractiveData(
                commit_index_one_based=int(m.group(1)),
                total_commits_in_stack=int(m.group(2)),
            )
        return None

    def stringify(self) -> str:
        return f"{self.commit_index_one_based}/{self.total_commits_in_stack}"


BranchPushResult = Literal["pushed", "up-to-date"]

BranchType = Literal["base", "head"]

PrUpsertResult = Literal["created", "updated", "up-to-date", "reopened"]

PrReviewDecision = Literal["APPROVED", "REVIEW_REQUIRED", "CHANGES_REQUESTED"]

CommitUpdateResult = Literal["updated", "up-to-date"]

T = TypeVar("T")


class Main:
    debug: bool = False
    debug_force_push_branches: bool = False
    login: str
    remote: str
    remote_base_branch: str = "master"

    #
    # Main entry point.
    #
    def run(self):
        self.debug_log_argv()

        parser = argparse.ArgumentParser(
            description="Pushes local commits as stacked PRs on GitHub and keeps them in sync.",
        )
        parser.add_argument(
            "--debug",
            default=False,
            action="store_true",
            help="print git and gh command lines",
        )
        parser.add_argument(
            "--debug-force-push-branches",
            default=False,
            action="store_true",
            help="if passed, forces all branches to be re-created and re-pushed",
        )
        args = parser.parse_args()

        in_rebase_interactive = InRebaseInteractiveData.parse(
            os.environ.get(INTERNAL_IN_REBASE_INTERACTIVE_VAR, "")
        )

        self.debug = args.debug
        self.debug_force_push_branches = args.debug_force_push_branches

        if not in_rebase_interactive:
            self.self_update()
            # For debug purposes only.
            self.shell_no_throw(["git", "--version"])
            self.shell_no_throw(["git", "status"])
            self.shell_no_throw(["git", "log", "--graph", "--decorate", "-3"])

        # Below is the real work.
        self.login = self.cache_through(
            "gh_get_current_login",
            self.gh_get_current_login,
        )
        self.remote = self.cache_through(
            "git_get_current_remote",
            self.git_get_current_remote,
        )
        self.remote_base_branch = self.cache_through(
            "git_get_current_remote_base_branch",
            self.git_get_current_remote_base_branch,
        )
        if in_rebase_interactive:
            self.run_in_rebase_interactive(data=in_rebase_interactive)
        else:
            self.run_all()
        print("")

    #
    # Runs the sync for only the top commit. This is an internal command which
    # is used during interactive rebase.
    #
    def run_in_rebase_interactive(self, *, data: InRebaseInteractiveData):
        remote_commit = self.git_get_commits(
            latest_ref=f"remotes/{self.remote}/{self.remote_base_branch}",
            count_back_in_time=1,
        )[0]
        commits = self.git_get_commits(latest_ref="HEAD", count_back_in_time=2)
        if len(commits) < 2:
            raise UserException("The repository must have at least 2 commits")
        commit, prev_commit = commits[0], commits[1]

        self.print_header(f"Processing commit: {self.clean_title(commit.title)}")

        if prev_commit.hash != remote_commit.hash:
            prev_commit, result = self.process_commit_push_branch(commit=prev_commit)
            self.print_branch_result(
                type="base",
                branch=str(prev_commit.branch),
                result=result,
            )
        else:
            self.print_branch_result(
                type="base",
                branch=self.remote_base_branch,
                result="up-to-date",
            )
            prev_commit.branch = None

        commit, result = self.process_commit_push_branch(commit=commit)
        self.print_branch_result(type="head", branch=str(commit.branch), result=result)

        new_pr_title = commit.title
        new_pr_body = None
        new_pr_fixes_accidentally_merged_one = False

        if commit.url:
            pr = self.gh_get_pr(url=commit.url)
            if pr.state == "MERGED" and pr.base_branch.startswith(BRANCH_PREFIX):
                self.print_pr_accidentally_merged()
                commit.url = None
                new_pr_fixes_accidentally_merged_one = True
                new_pr_title = pr.title
                new_pr_body = pr.body

        if not commit.url:
            assert (
                commit.branch is not None
            ), f"commit {commit.hash} branch must be resolved"
            url, result = self.gh_create_pr(
                base_branch=prev_commit.branch,
                head_branch=commit.branch,
                title=new_pr_title,
                body=new_pr_body,
                is_middle_pr=(
                    data.commit_index_one_based != 1
                    and data.commit_index_one_based != data.total_commits_in_stack
                ),
            )
            if result != "up-to-date":
                self.print_pr_created(
                    comment=(
                        "instead of accidentally merged"
                        if new_pr_fixes_accidentally_merged_one
                        else None
                    )
                )
            commit.url = url

            result = self.git_update_current_commit_message(
                header_name=PR_HEADER,
                header_value=commit.url,
                header_comment=self.remote_base_branch,
            )
            if result != "up-to-date":
                self.print_commit_message_updated()

    #
    # Assuming all PRs in the stack already have PR URLs in their description,
    # pushes the updated branches and updates the PRs descriptions with the full
    # list of commits in the stack.
    #
    def run_all(self):
        commits = self.git_get_commits()
        if len(commits) == 0:
            self.print_header(
                f"There are no local commits on top of {self.remote}. Commit something and rerun."
            )
            return

        task_upsert_labels = Task(self.gh_upsert_labels)
        tasks_gh_get_pr = (
            dict(
                [
                    (url, Task(self.gh_get_pr, url=url))
                    for url in (c.url for c in reversed(commits) if c.url)
                ]
            )
            if not self.debug_force_push_branches
            else {}
        )
        task_upsert_labels.wait()
        prs_by_url = dict((url, task.wait()) for (url, task) in tasks_gh_get_pr.items())

        self.debug_log_commits(commits=commits, prs_by_url=prs_by_url)

        self.process_validate_commits(commits=commits, prs_by_url=prs_by_url)

        # Inject "Pull Request" URL to commit descriptions starting from the
        # commit which doesn't have it. This is a heavy-weighted process which
        # is run for each commit in an interactive rebase, starting from bottom
        # to the very top.
        commit_with_no_url: Commit | None = None
        commit_hashes_to_push_branch: list[str] = []
        for commit in reversed(commits):
            if self.debug_force_push_branches or not commit.url:
                commit_with_no_url = commit
                break
            else:
                pr = prs_by_url[commit.url]
                if pr.state == "MERGED" and pr.base_branch.startswith(BRANCH_PREFIX):
                    commit_with_no_url = commit
                    break
                else:
                    commit_hashes_to_push_branch.append(commit.hash)

        # Some commits have no related PRs (no GitHub URLs in the message)?
        # Create missing PRs and amend their messages (via rebase interactive).
        if commit_with_no_url:
            self.process_create_missing_prs(
                earliest_hash=commit_with_no_url.hash,
                commits=commits,
            )
            commits = self.git_get_commits()

        # Update PRs for commits; they now all have URLs. Do not push branches
        # for commits for which we have just created missing PRs above (if any),
        # i.e. only push branches for commit_hashes_to_push_branch. This allows
        # to not re-trigger GitHub Actions. Notice that these branches WILL be
        # pushed next time, because we updated the commit message (added "Pull
        # Request" header with the just-created PR URL there which is impossible
        # to predict in advance), i.e. the sequence is "push branch - create PR
        # - update commit message - push branch", but the last step of this
        # sequence is delayed till the next run, when the author has some other
        # updates to piggy-back likely.
        if not os.environ.get(INTERNAL_SKIP_UPDATE_PRS_VAR):
            self.process_update_existing_prs(
                commits=commits,
                commit_hashes_to_push_branch=commit_hashes_to_push_branch,
            )

    #
    # Checks that the tool can process this stack of commits at all.
    #
    def process_validate_commits(
        self,
        *,
        commits: list[Commit],
        prs_by_url: dict[str, Pr],
    ):
        commits_chronological = list(reversed(commits))
        for i, commit in list(enumerate(commits_chronological))[1:]:
            pr = prs_by_url.get(commit.url, None) if commit.url else None
            if pr and pr.auto_merge_status == "ENABLED":
                prev_commit = commits_chronological[i - 1]
                prev_pr = (
                    prs_by_url.get(prev_commit.url, None) if prev_commit.url else None
                )
                if not prev_pr or prev_pr.head_branch != pr.base_branch:
                    raise UserException(
                        f"PR {pr.url} is auto-mergeable.\n"
                        + "I can't update it at GitHub without risking to auto-merge to an wrong branch.\n"
                        + "Please disable auto-merge for the PR and try again."
                    )

    #
    # Starting from commit with hash earliest_hash which has no PR URL in the
    # description, creates the missing PRs and updates commits descriptions with
    # the returned URL.
    #
    def process_create_missing_prs(
        self,
        *,
        earliest_hash: str,
        commits: list[Commit],
    ):
        try:
            commits_to_rebase = list(
                dropwhile(lambda c: c.hash != earliest_hash, reversed(commits))
            )
            assert (
                commits_to_rebase
            ), f"earliest_hash={earliest_hash} must be in commits={commits}"
            cmd = shlex.join(
                [
                    __file__,
                    *(["--debug"] if self.debug else []),
                    *(
                        ["--debug-force-push-branches"]
                        if self.debug_force_push_branches
                        else []
                    ),
                ]
            )
            todo = "".join(
                [
                    f"pick {c.hash} {c.title}\n"
                    + f"exec {INTERNAL_IN_REBASE_INTERACTIVE_VAR}="
                    + shlex.quote(
                        InRebaseInteractiveData(
                            commit_index_one_based=(
                                len(commits) - len(commits_to_rebase) + i + 1
                            ),
                            total_commits_in_stack=len(commits),
                        ).stringify()
                    )
                    + f" {cmd}\n"
                    for [i, c] in enumerate(commits_to_rebase)
                ]
            )
            self.git_rebase_interactive_exec(
                earliest_hash=earliest_hash,
                skip_res=[
                    r"^You can fix the problem, and then run$",
                    r"^\s*git rebase --continue$",
                ],
                todo=f"\n{todo}",
            )
        except (CalledProcessError, KeyboardInterrupt) as e:
            self.shell_no_throw(["git", "rebase", "--abort"])
            raise e

    #
    # Iterates over the list of commits with URLs and pushes their branches to
    # update the corresponding PRs.
    #
    def process_update_existing_prs(
        self,
        *,
        commits: list[Commit],
        commit_hashes_to_push_branch: list[str],
    ):
        # We must iterate from the oldest commit to the newest one, because
        # previous commit PR's branch becomes the next commit PR's base branch.
        commits_chronological = list(reversed(commits))
        for i, commit in enumerate(commits_chronological):
            self.print_header(f"\nUpdating PR: {self.clean_title(commit.title)}")

            if commit.hash in commit_hashes_to_push_branch:
                commit, result = self.process_commit_push_branch(commit=commit)
                if result == "pushed":
                    self.print_branch_result(
                        type="head",
                        branch=str(commit.branch),
                        result=result,
                    )
                commits_chronological[i] = commit

            assert (
                commit.url is not None
            ), f"commit {commit.hash} PR url is expected to be in the message at this point"
            pr, result = self.process_update_pr(
                prev_commit=commits_chronological[i - 1] if i > 0 else None,
                commit=commit,
                commits=commits,
            )
            self.print_pr_result(
                url=pr.url,
                result=result,
                review_decision=pr.review_decision,
            )
            commits_chronological[i].branch = pr.head_branch

    #
    # Pushes an existing branch (it we know this commit's PR URL by querying
    # GitHub), or creates a new branch based on commit title and pushes it.
    #
    def process_commit_push_branch(
        self,
        *,
        commit: Commit,
    ) -> tuple[Commit, BranchPushResult]:
        if commit.url:
            pr = self.gh_get_pr(url=commit.url)
            commit.branch = pr.head_branch
        else:
            commit.branch = self.build_branch_name(
                title=commit.title,
                commit_hash=commit.hash,
            )
        pushed = self.git_push_branch(branch=commit.branch, hash=commit.hash)
        return commit, pushed

    #
    # Updates PR fields:
    # - base branch (in case the commits were reordered, or some of them were
    #   merged into the remote, so the the beginning of the stack started
    #   pointing not to a branch, but to a remote tip)
    # - full stack list in the description
    # - git-grok related labels
    #
    # It's BTW not possible to update the head branch once PR is created.
    #
    def process_update_pr(
        self,
        *,
        prev_commit: Commit | None,
        commit: Commit,
        commits: list[Commit],
    ) -> tuple[Pr, PrUpsertResult]:
        pr_numbers: list[int] = []
        pr_number_current: int | None = None
        for c in commits:
            assert (
                c.url is not None
            ), f"commit {c.hash} PR URL is expected to be in the message at this point"
            if m := re.search(r"/(\d+)$", c.url):
                pr_numbers.append(int(m.group(1)))
                if c.hash == commit.hash:
                    pr_number_current = int(m.group(1))
        assert (
            commit.url is not None
        ), f"commit {commit.hash} PR URL is expected to be in the message at this point"
        return self.gh_update_pr(
            url=commit.url,
            base_branch=prev_commit.branch if prev_commit else None,
            pr_numbers=pr_numbers,
            pr_number_current=pr_number_current,
        )

    #
    # Returns current GitHub login.
    #
    def gh_get_current_login(self) -> str:
        return self.shell(["gh", "api", "user", "--jq", ".login"])

    #
    # Returns current git folder remote (most often "origin").
    #
    def git_get_current_remote(self) -> str:
        [_, symbolic_ref, _] = self.shell_no_throw(
            ["git", "symbolic-ref", "-q", "HEAD"]
        )
        if not symbolic_ref:
            raise UserException(
                'To run git-grok, you must be on a branch. Check your "git status".'
            )
        push_short = self.shell(
            ["git", "for-each-ref", "--format=%(push:short)", symbolic_ref]
        )
        if not (m := re.match(r"^([^/]+)/.+$", push_short)):
            raise UserException(
                f'fatal: No configured push destination for symbolic ref "{symbolic_ref}".\n'
                + "\n"
                + "Git infers the current remote from the branch name using one of the following ways:\n"
                + '1. It checks whether "git config branch.<branch>.remote" is set explicitly.\n'
                + '2. Or, if "git config push.default" is "current" or "matching", there must be\n'
                + "   only one remote configured.\n"
            )
        return m.group(1)

    #
    # Returns the current remote branch name on GitHub.
    #
    def git_get_current_remote_base_branch(self) -> str:
        branch = self.shell(["git", "branch", "--show-current"])
        if not branch:
            path = ".git/rebase-merge/head-name"
            if file := find_file_in_parents(path):
                branch = open(file).readline().strip()
                if not (m := re.match(r"refs/heads/(.+)", branch)):
                    raise UserException(f"File {path} doesn't contain refs/heads/*")
                branch = m.group(1)
            else:
                raise UserException(
                    f"You must be on a branch or in an interactive rebase mode."
                )
        return branch

    #
    # Returns current git folder owner name and repository name.
    #
    def gh_get_current_repo_owner_and_name(self) -> tuple[str, str]:
        out_str = self.shell(
            [
                "gh",
                "repo",
                "view",
                "--json",
                "owner,name",
                "--jq",
                "[.owner.login,.name]",
            ]
        )
        return tuple(json.loads(out_str))

    #
    # Pre-creates git-grok related labels.
    #
    def gh_upsert_labels(self):
        self.shell(
            [
                "gh",
                "label",
                "create",
                MIDDLE_PR_LABEL,
                "-d",
                MIDDLE_PR_LABEL_DESCRIPTION,
                "-c",
                MIDDLE_PR_LABEL_COLOR,
                "--force",
            ],
        )

    #
    # Creates a GitHub PR between two existing branches. The description of the
    # new PR will NOT include the body suffix with the list of all PRs in the
    # stack, since we don't know all URLs in this list yet.
    #
    def gh_create_pr(
        self,
        *,
        base_branch: str | None,
        head_branch: str,
        title: str,
        body: str | None,
        is_middle_pr: bool,
    ) -> tuple[str, PrUpsertResult]:
        if not base_branch:
            base_branch = self.remote_base_branch

        if body is not None:
            body_file = TMP_BODY_FILE
            with open(body_file, "w+") as file:
                file.write(body)
        else:
            body_file = find_file_in_parents(".github/pull_request_template.md")

        cmd = [
            "gh",
            "pr",
            "create",
            "--base",
            base_branch,
            "--head",
            head_branch,
            *(["--label", MIDDLE_PR_LABEL] if is_middle_pr else []),
            "--title",
            title,
            *(["--body-file", body_file] if body_file else ["--body", ""]),
        ]

        attempt = 0
        while True:
            returncode, output, stderr = self.shell_no_throw(cmd)
            if returncode == 0:
                return output, "created"

            if m := re.match(r".* already exists[^\n]\n(\S+)", stderr, flags=re.S):
                return m.group(1), "up-to-date"

            if attempt < 3 and (
                m := re.match(r".* was submitted too quickly", stderr, flags=re.S)
            ):
                dt = 3 + random.random() * 3
                self.debug_log_text(text=f"Waiting for {dt} seconds and retrying...")
                sleep(dt)
                attempt += 1
                continue

            raise CalledProcessError(
                returncode=returncode,
                cmd=cmd,
                output=output,
                stderr=stderr,
            )

    #
    # Updates base_branch and description suffix of the PR.
    #
    def gh_update_pr(
        self,
        *,
        url: str,
        base_branch: str | None,
        pr_numbers: list[int],
        pr_number_current: int | None,
    ) -> tuple[Pr, PrUpsertResult]:
        if base_branch is None:
            base_branch = self.remote_base_branch

        pr = self.gh_get_pr(url=url)
        new_body = body_suffix_upsert(pr.body, pr_numbers, pr_number_current)
        is_middle_pr = len(pr_numbers) > 0 and pr.number not in (
            pr_numbers[0],
            pr_numbers[-1],
        )

        if (
            pr.base_branch == base_branch
            and pr.body == new_body
            and pr.state == "OPEN"
            and (MIDDLE_PR_LABEL in pr.labels) == is_middle_pr
        ):
            return pr, "up-to-date"

        self.cache_clean(url)

        upsert_result = "updated"

        if pr.state != "OPEN":
            upsert_result = "reopened"
            self.shell(
                [
                    "gh",
                    "pr",
                    "reopen",
                    url,
                    "--comment",
                    "Reopened by git-grok.",
                ],
                input=new_body,
            )

        self.shell(
            [
                "gh",
                "pr",
                "edit",
                url,
                "--base",
                base_branch,
                *(
                    ["--add-label", MIDDLE_PR_LABEL]
                    if is_middle_pr and MIDDLE_PR_LABEL not in pr.labels
                    else (
                        ["--remove-label", MIDDLE_PR_LABEL]
                        if not is_middle_pr and MIDDLE_PR_LABEL in pr.labels
                        else []
                    )
                ),
                "--body-file",
                "-",
            ],
            input=new_body,
        )

        pr.base_branch = base_branch
        pr.body = new_body
        return pr, upsert_result

    #
    # Reads PR info from GitHub.
    #
    # We read PRs one by one and not in GraphQL-bulk for 3 reasons:
    # - Granular caching. We use cache_through() for each PR, so in the
    #   consequent interactive rebase call, it will be reused (and also, it will
    #   be reused in other places where we need to read a PR info).
    # - It is not much worse in performance, because we run the initial
    #   gh_get_pr() in parallel, in Task threads.
    # - Simplicity reason: we want to avoid GraphQL code duplication with the
    #   logic of gh_get_pr().
    #
    def gh_get_pr(self, *, url: str) -> Pr:
        out_str = self.cache_through(
            url,
            lambda: self.shell(
                [
                    "gh",
                    "pr",
                    "view",
                    url,
                    "--json",
                    "number,title,body,baseRefName,headRefName,url,reviewDecision,state,labels,autoMergeRequest",
                ],
            ),
        )
        value = json.loads(out_str)
        return Pr(
            number=int(value["number"]),
            title=value["title"],
            body=value["body"],
            base_branch=re.sub(r"^refs/heads/", "", value["baseRefName"]),
            head_branch=re.sub(r"^refs/heads/", "", value["headRefName"]),
            url=value["url"],
            review_decision=value["reviewDecision"],
            state=value["state"],
            auto_merge_status="ENABLED" if value["autoMergeRequest"] else "DISABLED",
            labels=[label["name"] for label in value["labels"]],
        )

    #
    # Returns parsed commits between two refs in reverse-chronological order
    # (newest commits first, oldest last, as they're shown in "git log").
    #
    def git_get_commits(
        self,
        *,
        latest_ref: str | None = None,
        earliest_ref: str | None = None,
        count_back_in_time: int | None = None,
    ) -> list[Commit]:
        if latest_ref is None:
            latest_ref = "HEAD"
        if earliest_ref is None:
            earliest_ref = f"remotes/{self.remote}/{self.remote_base_branch}"
        if count_back_in_time:
            out = self.shell(["git", "log", latest_ref, f"-{count_back_in_time}"])
        else:
            out = self.shell(["git", "log", f"{earliest_ref}..{latest_ref}"])
        commits: list[Commit] = []
        for commit in re.split(r"^(?=commit )", out, flags=re.M)[1:]:
            try:

                if not (
                    m := re.match(
                        r"commit (\w+)[^\n]*\n(.*?)\n\n(.*)$", commit, flags=re.S
                    )
                ):
                    raise UserException("Can't parse commit-headers-body.")

                hash, _headers, body = m.group(1), m.group(2), m.group(3).rstrip()

                if not (m := re.match(r"([^\n]+)\n?(.*)$", body, flags=re.S)):
                    raise UserException(f"Can't extract commit title and description.")
                title, description = m.group(1).strip(), m.group(2)

                m = re.search(PR_HEADER_RE, description, flags=re.M)
                url = m.group(1).strip() if m else None
                expected_base_branch = m.group(2).strip() if m and m.group(2) else None

                # People often times cherry-pick commits from one branch to
                # another to e.g. ship hot-fixes in production or staging
                # branch. In this case, we must ignore the PR URL, because along
                # with this cherry-pick, the commit message (with existing PR
                # URL) is copied, so we don't want to have a collision.
                if (
                    expected_base_branch is not None
                    and expected_base_branch != self.remote_base_branch
                ):
                    url = None
            except UserException as e:
                raise UserException(f"{str(e)} Commit:\n<<<\n{commit.strip()}\n>>")
            except BaseException as e:
                tb = traceback.format_exc()
                raise UserException(f"{tb}\nCommit:\n<<<\n{commit.strip()}\n>>\n\n")

            commits.append(
                Commit(
                    hash=hash,
                    url=url,
                    title=title,
                    description=description,
                    branch=None,
                )
            )
        return commits

    #
    # Pushes a branch to remote GitHub.
    #
    def git_push_branch(self, *, branch: str, hash: str) -> BranchPushResult:
        # Git push is a quick no-op on GitHub end if the branch isn't changed
        # (it prints "Everything up-to-date"), so we always push and then verify
        # the output for the status (instead of fetching from the remote and
        # comparing the branch'es tip commit hash).
        out = self.shell(
            [
                "git",
                "push",
                "-f",
                self.remote,
                f"{hash}:refs/heads/{branch}",
            ],
            stderr_to_stdout=True,
        )
        return (
            "up-to-date"
            if re.match(r"^[^\n]+up-to-date", out, flags=re.S)
            else "pushed"
        )

    #
    # Runs an interactive rebase with the provided shell command.
    #
    def git_rebase_interactive_exec(
        self,
        *,
        earliest_hash: str,
        skip_res: list[str] = [],
        todo: str,
    ):
        self.shell_passthrough(
            [
                "git",
                "rebase",
                "--quiet",
                "--interactive",
                f"{earliest_hash}^",
            ],
            env={"GIT_SEQUENCE_EDITOR": f"echo {shlex.quote(todo)} >"},
            skip_res=[r"Executing: ", *skip_res],
        )

    #
    # Updates the message suffix (pointing to a PR URL) of the current commit
    # which is at the moment selected (activated) with interactive rebase.
    #
    def git_update_current_commit_message(
        self,
        *,
        header_name: str,
        header_value: str,
        header_comment: str | None = None,
    ) -> CommitUpdateResult:
        new_header = f"{header_name}: {header_value}"
        if header_comment:
            new_header += f" ({header_comment})"
        message = self.shell(
            ["git", "show", "--pretty=format:%B", "--no-patch"],
            no_rstrip=True,
        )
        if m := re.search(rf"^{header_name}: [^\n]+", message, flags=re.M):
            new_message = message.replace(m[0], new_header)
        else:
            new_message = f"{message.rstrip()}\n\n{new_header}"
        if new_message != message:
            self.shell(
                ["git", "commit", "--amend", "--no-verify", "-F", "-"],
                input=new_message,
            )
            return "updated"
        else:
            return "up-to-date"

    #
    # Runs a shell command returning results.
    #
    def shell(
        self,
        cmd: list[str],
        *,
        no_rstrip: bool = False,
        input: str | None = None,
        stderr_to_stdout: bool = False,
        env: dict[str, str] | None = None,
        comment: str | None = None,
    ) -> str:
        out = None
        returncode = 0
        time_start = time()
        try:
            out = check_output(
                cmd,
                text=True,
                stderr=subprocess.STDOUT if stderr_to_stdout else subprocess.PIPE,
                input=input,
                env={**os.environ, **env} if env else None,
            )
            return out if no_rstrip else out.rstrip()
        except CalledProcessError as e:
            returncode = e.returncode
            out = "\n".join(s for s in [e.stdout, e.stderr] if s)
            raise
        finally:
            self.debug_log_shell_command(
                cmd=cmd,
                env=env,
                out=out,
                took_s=time() - time_start,
                returncode=returncode,
                comment=comment,
            )

    #
    # Same as shell(), but never throws and returns an exit code along with the
    # outputs instead.
    #
    def shell_no_throw(
        self,
        cmd: list[str],
        *,
        no_rstrip: bool = False,
        env: dict[str, str] | None = None,
        comment: str | None = None,
    ) -> tuple[int, str, str]:
        stdout = ""
        stderr = ""
        returncode = None
        time_start = time()
        try:
            proc = Popen(
                cmd,
                text=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                env={**os.environ, **env} if env else None,
            )
            stdout, stderr = proc.communicate()
            if not no_rstrip:
                stdout = stdout.rstrip()
                stderr = stderr.rstrip()
            returncode = proc.returncode
            return (
                proc.returncode,
                stdout,
                stderr,
            )
        finally:
            self.debug_log_shell_command(
                cmd=cmd,
                env=env,
                out="\n".join(s for s in [stdout, stderr] if s),
                took_s=time() - time_start,
                returncode=returncode,
                comment=comment,
            )

    #
    # Runs a shell command, but prints its output as is.
    #
    def shell_passthrough(
        self,
        cmd: list[str],
        *,
        env: dict[str, str] | None = None,
        skip_res: list[str] = [],
        comment: str | None = None,
    ):
        out = ""
        self.debug_log_shell_command(
            cmd=cmd,
            env=env,
            out="",
            took_s=0,
            returncode=None,
            comment=comment,
        )
        with Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,  # to apply skip_res to stderr as well
            text=True,
            bufsize=1,
            env={**os.environ, **env} if env else None,
        ) as pipe:
            assert pipe.stdout is not None
            for line in pipe.stdout:
                line = line.rstrip()
                if not line:
                    continue
                out += line + "\n"
                if not any(re.search(r, line, flags=re.S) for r in skip_res):
                    print(line)
                    sys.stdout.flush()
            returncode = pipe.wait()
            if returncode != 0:
                raise CalledProcessError(returncode=returncode, cmd=cmd)

    #
    # Tries to self-update the tool by pulling from git.
    #
    def self_update(self):
        dir = os.path.dirname(os.path.realpath(__file__))
        if not os.path.exists(f"{dir}/.git"):
            return
        self.shell_no_throw(
            ["sh", "-c", f"cd {shlex.quote(dir)} && git pull --rebase"],
            comment="self-update",
        )

    #
    # Cleans a title from useless prefix/suffix.
    #
    def clean_title(self, title: str) -> str:
        title = title.strip()
        title = re.sub(r"^\w+[()\[\]\w]*:\s+", "", title)
        title = re.sub(r"\[[-\w]+\]$", "", title)
        title = title.strip()
        max_len = max(
            MIN_TITLE_LEN_IN_PRINT,
            TERMINAL_SIZE.columns - 22,
        )
        if len(title) > max_len:
            title = title[0:max_len] + "…"
        return title

    #
    # Builds branch name from commit title.
    #
    def build_branch_name(self, *, title: str, commit_hash: str) -> str:
        branch = title
        branch = branch.strip()
        branch = re.sub(r"\[[-\w]+\]$", "", branch)
        branch = branch.lower()
        branch = re.sub(r"^\W+|\W+$", "", branch)
        branch = re.sub(r"\W+", "-", branch)
        branch += f"-to-{self.remote_base_branch}-{commit_hash[0:4]}"
        return f"{BRANCH_PREFIX}{self.login}/{branch}"

    #
    # Prints a status after a branch push attempt happened.
    #
    def print_branch_result(
        self,
        *,
        type: BranchType,
        branch: str,
        result: BranchPushResult,
    ):
        max_len = max(
            MIN_BRANCH_LEN_IN_PRINT,
            TERMINAL_SIZE.columns - (11 + 4 + len(self.remote) + 10) - 5,
        )
        if len(branch) > max_len:
            branch = branch[0:max_len] + "…"
        print(f"  ── {type}: {self.remote}/{branch} ({result})")
        sys.stdout.flush()

    #
    # Prints a "PR created" message.
    #
    def print_pr_created(self, *, comment: str | None = None):
        # ATTENTION: we DO NOT print the newly created PR URL here, because it
        # lacks the footer with links to all other PRs in the stack yet. If
        # someone starts editing it before that footer is added (later, during
        # the next stage), then they'll risk to lose the text! So we have no
        # choice but to force the user to wait.
        print(f"  ── new Pull Request created" + (f" ({comment})" if comment else ""))
        sys.stdout.flush()

    #
    # Prints a "PR was accidentally merged" message.
    #
    def print_pr_accidentally_merged(self):
        print(f"  💀 this PR was accidentally merged into {BRANCH_PREFIX}*, recreating")
        sys.stdout.flush()

    #
    # Prints a status after a commit message was updated locally.
    #
    def print_commit_message_updated(self):
        print(f"  ── updated commit message")
        sys.stdout.flush()

    #
    # Prints a status after a PR was created/updated on GitHub.
    #
    def print_pr_result(
        self,
        *,
        url: str,
        result: PrUpsertResult,
        review_decision: PrReviewDecision,
    ):
        icon = (
            review_decision == "APPROVED"
            and "🟢"
            or review_decision == "CHANGES_REQUESTED"
            and "🔴"
            or "🟡"
        )
        print(f"  {icon} {url} ({result})")
        sys.stdout.flush()

    #
    # Prints the heading message of an operation.
    #
    def print_header(self, header: str):
        print(header)
        sys.stdout.flush()

    #
    # Logs the current command line arguments.
    #
    def debug_log_argv(self):
        text = shlex.join(sys.argv).strip()
        for var in [INTERNAL_IN_REBASE_INTERACTIVE_VAR, INTERNAL_SKIP_UPDATE_PRS_VAR]:
            value = os.environ.get(var)
            if value:
                text = f"{var}={shlex.quote(value)} {text}"
        self.debug_log_text(text=text)

    #
    # Logs a list of commits and their corresponding PR statuses.
    #
    def debug_log_commits(
        self,
        *,
        commits: list[Commit],
        prs_by_url: dict[str, Pr],
    ):
        max_url_len = max(
            [len(c.url) for c in commits if c.url],
            default=0,
        )
        max_state_len = max(
            [len(pr.state) for pr in prs_by_url.values()],
            default=0,
        )
        max_head_branch_len = max(
            [len(pr.head_branch) for pr in prs_by_url.values()],
            default=0,
        )
        lines: list[str] = []
        for c in commits:
            url = c.url or "-"
            pr = prs_by_url.get(url)
            state = pr.state if pr else "-"
            head_branch = pr.head_branch if pr else "-"
            lines.append(
                f"{c.hash} | {url.ljust(max_url_len)} | {head_branch.ljust(max_head_branch_len)} | {state.ljust(max_state_len)} | {c.title}"
            )
        self.debug_log_text(text="\n".join(lines))

    #
    # Logs a command which is run by the tool.
    #
    def debug_log_shell_command(
        self,
        *,
        cmd: list[str],
        env: dict[str, str] | None,
        out: str | None,
        took_s: float,
        returncode: int | None,
        comment: str | None = None,
    ):
        rows: list[tuple[tuple[int, int, int], str]] = []
        rows.append(
            (
                DEBUG_COLOR_GRAY_1,
                "$ "
                + (
                    " ".join([f"{k}={shlex.quote(v)}" for (k, v) in env.items()]) + " "
                    if env
                    else ""
                )
                + shlex.join(cmd).strip()
                + (f" # took {int(took_s * 1000)} ms" if took_s else "")
                + (f" # returncode={returncode}" if returncode else "")
                + (
                    f" # ran in a parallel thread"
                    if current_thread() is not main_thread()
                    else ""
                )
                + (f" # {comment}" if comment else ""),
            )
        )
        if out:
            rows.append(
                (
                    DEBUG_COLOR_GRAY_2,
                    re.sub(
                        r"^",
                        "  ",
                        re.sub(r"\n([| \t]*\n)+", "\n", out.rstrip()),
                        flags=re.M,
                    ),
                )
            )

        if os.environ.get(INTERNAL_IN_REBASE_INTERACTIVE_VAR):
            rows = [(row[0], re.sub(r"^", "> ", row[1], flags=re.M)) for row in rows]

        self.debug_log_text(text="\n".join(row[1] for row in rows))
        if self.debug:
            for row in rows:
                print(colored(*row[0], row[1]))
            sys.stdout.flush()

    #
    # Logs a text block (prepended by date) to the debug file.
    #
    def debug_log_text(self, *, text: str):
        try:
            with open(DEBUG_FILE, "a+") as file:
                file.write(f"=== {datetime.now()}\n")
                file.write(f"{text.rstrip()}\n")
                file.write("\n")
        except:
            pass

    #
    # Caches the return value of a function in environment and returns it next time
    # it's requested.
    #
    def cache_through(self, key: str, func: Callable[[], str]) -> str:
        key = hashify(key)
        var = f"{INTERNAL_ENV_VAR_PREFIX}_{key}"
        value = os.environ.get(var)
        if value is None:
            value = func()
            os.environ[var] = value
        else:
            self.debug_log_shell_command(
                cmd=["printenv", var],
                env=None,
                out=value,
                took_s=0,
                returncode=None,
                comment="cache hit",
            )
        return value

    #
    # Removes the cached value for the key.
    #
    def cache_clean(self, key: str):
        key = hashify(key)
        var = f"{INTERNAL_ENV_VAR_PREFIX}_{key}"
        os.environ.pop(var, None)


#
# Splits a list into chunks of size n.
#
def chunk(lst: list[T], n: int) -> list[list[T]]:
    res: list[list[T]] = []
    for i in range(0, len(lst), n):
        res.append(lst[i : i + n])
    return res


#
# Returns a colored text.
#
def colored(r: int, g: int, b: int, text: str) -> str:
    return f"\033[38;2;{r};{g};{b}m{text}\033[0m"


#
# Traverse the filesystem from the current directory to root trying to find a
# matching relative file path in parent directories.
#
def find_file_in_parents(file: str) -> str | None:
    path = os.getcwd()
    old_path = ""
    while old_path != path:
        full = os.path.join(path, file)
        if os.path.exists(full):
            return full
        old_path = path
        path = os.path.dirname(path)
    return None


#
# If there is no body suffix in the body, appends it. Otherwise, replaces the
# previous occurrence of the body suffix (heuristically found) with the new one.
#
def body_suffix_upsert(
    body: str,
    pr_numbers: list[int],
    pr_number_current: int | None,
) -> str:
    items = [
        f"- {'➡ ' if pr_number == pr_number_current else ''}#{pr_number}"
        for pr_number in pr_numbers
    ]
    suffix = (
        BODY_SUFFIX_TITLE + "\n" + "\n".join(items) + "\n\n" + BODY_SUFFIX_FOOTER + "\n"
    )
    if re.search(BODY_SUFFIX_RE, body, flags=re.M | re.I | re.X):
        return re.sub(BODY_SUFFIX_RE, suffix, body, flags=re.M | re.I | re.X)
    return body.rstrip() + "\n\n" + suffix


#
# Hashes a text, but keeps it recognizable. Seems like in some shells, we can't
# have env variables with arbitrary characters, so we have to normalize
# (otherwise, some tests fail in GitHub Actions).
#
def hashify(text: str) -> str:
    return (
        re.sub(r"^_+|_+$", "", re.sub(r"[^A-Za-z0-9]+", "_", text))
        + "_"
        + hashlib.sha256(text.encode()).hexdigest()[0:8]
    )


#
# Runs a function in a separate thread. To wait for its termination and get its
# return value, call wait() method. If the function raises an exception, it will
# be re-raised in the calling thread.
#
class Task(Generic[T]):
    _result: T
    _error: BaseException | None = None
    _thread: Thread

    def __init__(self, target: Callable[..., T], *args: ..., **kwargs: ...):
        def target_wrapper():
            try:
                self._result = target(*args, **kwargs)
            except BaseException as e:
                self._error = e

        self._thread = Thread(target=target_wrapper)
        self._thread.start()

    def wait(self) -> T:
        self._thread.join()
        if self._error:
            raise self._error
        return self._result


#
# If raised, the stacktrace is not shown.
#
class UserException(Exception):
    pass


if __name__ == "__main__":
    try:
        sys.exit(Main().run())
    except UserException as e:
        print(re.sub(r"^", "❌ ", str(e), flags=re.M))
        sys.exit(1)
    except CalledProcessError as e:
        print(
            f'Command "{shlex.join(e.cmd)}" returned status {e.returncode}.'
            + (f"\n{e.stdout}" if e.stdout else "")
            + (f"\n{e.stderr}" if e.stderr else ""),
            file=sys.stderr,
        )
        sys.exit(2)
